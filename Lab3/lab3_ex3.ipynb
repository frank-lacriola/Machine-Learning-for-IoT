{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660f6cdb-97cf-428d-8853-0383e10d5fe1",
   "metadata": {},
   "source": [
    "# This is 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2249230b-bd99-42d6-9bf0-7bde7f25d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from board import D4\n",
    "import adafruit_dht\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af457c19-a948-471e-9838-016d54c104de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, required=True)\n",
    "args = parser.parse_args(['--model=ex1'])\n",
    "\n",
    "#converter = tf.lite.TFLiteConverter.from_saved_model('home/pi/WORK_DIR/notebooks/Ex_Frank/LABS/Lab3/saved_models/')\n",
    "#tflite_model = converter.convert()\n",
    "# The value returned by convert is a “bytes”\n",
    "# object which contains the serialized model, and\n",
    "# can be directly written to a binary file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c329ed8-4308-46e2-9229-d5f01460b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_x:0\n",
      "Input shape: [1 6 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"{}.tflite\".format(args.model))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13124737-b217-4325-a492-845bcabee5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[37.2885]]\n",
      "Measured values: 36.0.15.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b062940daab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Measured values: {:.1f}.{:.1f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted: {:.1f},{:.1f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "window = np.zeros([1, 6, 2], dtype=np.float32)\n",
    "true_values = np.zeros(2, dtype=np.float32)\n",
    "\n",
    "\n",
    "dht_device = adafruit_dht.DHT11(D4)\n",
    "\n",
    "MEAN = np.array([9.107597, 75.904076], dtype=np.float32)\n",
    "STD = np.array([ 8.654227, 16.557089], dtype=np.float32)\n",
    "\n",
    "while True:\n",
    "    for i in range(7):\n",
    "        temperature = dht_device.temperature\n",
    "        humidity = dht_device.humidity\n",
    "        \n",
    "        if i<6:\n",
    "            window[0, i, 0] = np.float32(temperature)\n",
    "            window[0, i, 1] = np.float32(humidity)\n",
    "        if i==6:\n",
    "            true_values[0] = np.float32(temperature)\n",
    "            true_values[1] = np.float32(humidity)\n",
    "            \n",
    "            window = (window - MEAN) / STD\n",
    "            interpreter.set_tensor(input_details[0]['index'], window)\n",
    "            interpreter.invoke()\n",
    "            predicted = interpreter.get_tensor(output_details[0]['index'])\n",
    "            print(predicted)\n",
    "            \n",
    "            print('Measured values: {:.1f}.{:.1f}'.format(true_values[0], true_values[1]))\n",
    "            print('Predicted: {:.1f},{:.1f}'.format(predicted[0, 0], predicted[0, 1]))        \n",
    "        time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97e01e17-8baf-47c1-b8e1-3690766fc05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc5d29a0-4dc6-489b-b12d-3bbd4efc8884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WindowGenerator:\n",
    "    def __init__(self, input_width, label_options, mean, std):\n",
    "        self.input_width = input_width  # the number of samples contained in a single window\n",
    "        self.label_options = label_options\n",
    "        self.mean = tf.reshape(tf.convert_to_tensor(mean), [1, 1, 2])  # sec arg is the shape and during training the first dim is batch\n",
    "        self.std = tf.reshape(tf.convert_to_tensor(std), [1, 1, 2])\n",
    "\n",
    "    def split_window(self, features):\n",
    "        # here the assumption is that features already contains 7 values\n",
    "        inputs = features[:, :-1, :]  # we leave the last one as label, remember we have the batch at the first dim\n",
    "\n",
    "        if self.label_options < 2:\n",
    "            labels = features[:, -1, self.label_options]\n",
    "            labels = tf.expand_dims(labels, -1)\n",
    "            num_labels = 1\n",
    "        else:\n",
    "            labels = features[:, -1, :]\n",
    "            num_labels = 2\n",
    "\n",
    "        inputs.set_shape([None, self.input_width, 2])  # we set the batch dim as None because it will be needed later\n",
    "        labels.set_shape([None, num_labels])  # same for labels\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def normalize(self, features):\n",
    "        features = (features - self.mean) / (self.std + 1.e-6)  # we add a small quantity to avoid divisions by zero\n",
    "\n",
    "        return features\n",
    "\n",
    "    def preprocess(self, features):\n",
    "        inputs, labels = self.split_window(features)\n",
    "        inputs = self.normalize(inputs)  # we don't need to normalize labels\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def make_dataset(self, data, train):\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array( # this is what we need\n",
    "                data=data,\n",
    "                targets=None,\n",
    "                sequence_length=self.input_width+1,  # + label\n",
    "                sequence_stride=1,\n",
    "                batch_size=32)  # we'll try to change batch size later\n",
    "        ds = ds.map(self.preprocess)  # the preprocess will be applied to every batch\n",
    "        ds = ds.cache()\n",
    "\n",
    "        if train is True:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True) # 100 is the shuffling buffer size\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "class customMAE(keras.metrics.Metric):\n",
    "    def __init__(self, name='custom_MAE', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        # MAE: we need the sum --> total, and the count --> count to compute the mean\n",
    "        self.total = self.add_weight('total', initializer='zero', shape=(2,))\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "\n",
    "    # We have to iterate over all the dataset and update the state vars\n",
    "    # This is computed at every batch\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        error = tf.abs(y_pred-y_true)\n",
    "        error = tf.reduce_mean(error, axis=0)\n",
    "        self.total.assign_add(error)\n",
    "        self.count.assign_add(1.)\n",
    "        return\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.count.assign(tf.zeros_like(self.count))\n",
    "        self.total.assign(tf.zeros_like(self.total))\n",
    "        return\n",
    "\n",
    "    # after we have updated for all the dataset we return the result\n",
    "    def result(self):\n",
    "        result = tf.math.divide_no_nan(self.total, self.count)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "712b7f80-e7dc-4000-9138-20e19966ed85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-26-ae34ae061efc>:32 preprocess  *\n        inputs = self.normalize(inputs)  # we don't need to normalize labels\n    <ipython-input-26-ae34ae061efc>:26 normalize  *\n        features = (features - self.mean) / (self.std + 1.e-6)  # we add a small quantity to avoid divisions by zero\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1141 binary_op_wrapper\n        raise e\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1125 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:527 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10466 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:573 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Sub' Op has type float64 that does not match type int64 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-677ec39ad848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's adapt our input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ae34ae061efc>\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(self, data, train)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0msequence_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 batch_size=32)  # we'll try to change batch size later\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the preprocess will be applied to every batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \"\"\"\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-26-ae34ae061efc>:32 preprocess  *\n        inputs = self.normalize(inputs)  # we don't need to normalize labels\n    <ipython-input-26-ae34ae061efc>:26 normalize  *\n        features = (features - self.mean) / (self.std + 1.e-6)  # we add a small quantity to avoid divisions by zero\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1141 binary_op_wrapper\n        raise e\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:1125 binary_op_wrapper\n        return func(x, y, name=name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:527 subtract\n        return gen_math_ops.sub(x, y, name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py:10466 sub\n        \"Sub\", x=x, y=y, name=name)\n    /home/pi/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:573 _apply_op_helper\n        inferred_from[input_arg.type_attr]))\n\n    TypeError: Input 'y' of 'Sub' Op has type float64 that does not match type int64 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "# let's adapt our input\n",
    "generator = WindowGenerator(6, 2, input_data.mean(axis=0), input_data.std(axis=0))\n",
    "input_ds = generator.make_dataset(input_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7764852b-c608-447d-a8d8-04e2e21d6c08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float32' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5d1da1f4353e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#input_data = np.expand_dims(input_data, axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'float32' is not defined"
     ]
    }
   ],
   "source": [
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "input_data = tf.convert_to_tensor(input_data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18960c4a-1e04-4e1a-9ae3-6670f6300bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6ce89e4-54b5-4f3c-8a05-7a3dab855340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: [[471.6208]]\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()  # here the inference takes place (NN is executed)\n",
    "\n",
    "my_output = interpreter.get_tensor(output_details[0]['index'])  # returns value contained in the out buffer as np arrays\n",
    "print(\"Output:\", my_output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b96267e0-93d0-44c1-b4cd-597a21e17d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temperature    41\n",
       "Humidity       10\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ebf50-eb29-4c21-92bb-b2ddb740c46e",
   "metadata": {},
   "source": [
    "# Ex 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64a4c703-9010-44fe-8277-1d4685ef4b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mEx_Ciccio\u001b[0m/    nohup.out   rpi_requirements.txt\n",
      "\u001b[01;34mEx_Frank\u001b[0m/     \u001b[01;34mnotebooks\u001b[0m/  tensorflow-2.3.0-cp37-none-linux_armv7l.whl\n",
      "\u001b[01;34mEx_Gianluca\u001b[0m/  \u001b[01;34mpy37\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls home/pi/WORK_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "066a7de6-d71d-4487-9ac2-5eafbfcf2762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints' 'up' 'stop' 'no' 'go' 'left' 'down' 'yes' 'right']\n",
      "Audio shape without padding (None,)\n",
      "Audio shape with padding (16000,)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import wave\n",
    "from io import BytesIO\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "\n",
    "model = 'model'\n",
    "    \n",
    "interpreter = tf.lite.Interpreter(model_path='./models/{}.tflite'.format(model))\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b94815a9-2a3f-4aff-af17-13b5dd8bdf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_conv2d_9_input:0\n",
      "Input shape: [ 1 49 10  1]\n",
      "Output shape: [1 8]\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"home/pi/WORK_DIR/notebooks/Ex_Gianlu/LABs/LAB 3/data/mini_speech_commands\"\n",
    "\n",
    "mfcc_bool = True\n",
    "\n",
    "STFT_OPTIONS = {'frame_length': 256, 'frame_step': 128, 'mfcc': False}\n",
    "MFCC_OPTIONS = {'frame_length': 640, 'frame_step': 320, 'mfcc': True,\n",
    "                'lower_frequency': 20, 'upper_frequency': 4000, 'num_mel_bins': 40,\n",
    "                'num_coefficients': 10}\n",
    "\n",
    "if mfcc_bool:\n",
    "    options = MFCC_OPTIONS\n",
    "else:\n",
    "    options = STFT_OPTIONS\n",
    "\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')  # Return list of files matching the pattern\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "LABELS = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "LABELS = LABELS[LABELS != 'README.md'][:10]\n",
    "print(LABELS)\n",
    " \n",
    "    \n",
    "generator = SignalGenerator(LABELS, 16000, **options)\n",
    "input_dataset = generator.make_dataset(filenames[:10], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1c0cef09-73e3-4800-9ca4-4c21bcf5ab16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 49, 10, 1)\n",
      "Output: [[-7.3472733 -2.3088493 -5.558369  -6.477327   3.7452102 -6.8825917\n",
      "  -6.095357  -1.4488666]]\n",
      "True labels: tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for e in input_dataset:\n",
    "    elems = e[0]\n",
    "    elems = tf.expand_dims(elems, axis=0)\n",
    "    print(elems.shape)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], elems)\n",
    "\n",
    "    interpreter.invoke()  # here the inference takes place (NN is executed)\n",
    "\n",
    "    my_output = interpreter.get_tensor(output_details[0]['index'])  # returns value contained in the out buffer as np arrays\n",
    "    print(\"Output:\", my_output)\n",
    "    print(\"True labels:\", e[1])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9bb47f1f-f7da-4329-ad11-f4e8de18b05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n",
      "(49, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "for e in input_dataset:\n",
    "    print(e[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3806c68f-dff3-4341-9925-6cdf642484e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
