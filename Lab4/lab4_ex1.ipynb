{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70895ded-8619-4791-948e-2e738579de93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pi/WORK_DIR/notebooks/Ex_Frank/LABS\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0843f45-16f8-496c-9fe9-ad20fbc0bf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pi/WORK_DIR/notebooks/Ex_Frank/LABS'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15f0c3-6e21-4f98-8fe2-137a85c6026c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a361eeea-b5af-4493-b7da-328eaa433d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lab3.lab3_ex1 import WindowGenerator\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40052e0-0b7a-45db-b349-da96c8e169ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', type=str, help='model name among mlp cnn and lstm')\n",
    "parser.add_argument('--labels', type=int, default=0,\n",
    "                    help='0 for temp forecasting, 1 for hum forecasting, 2 or more for both')\n",
    "#parser.add_argument('--saved_model_dir', type=str, default=None)\n",
    "args = parser.parse_args(['--labels=2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48b70d4f-b6e3-4a51-8bc9-ca15135e40da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "zip_path = \"Lab3/data/jena_climate_2009_2016.csv.zip\"\n",
    "\n",
    "csv_path, _ = os.path.splitext(zip_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "column_indices = [2, 5]\n",
    "columns = df.columns[column_indices]\n",
    "data = df[columns].values.astype(np.float32)\n",
    "\n",
    "n = len(data)\n",
    "train_data = data[0:int(n * 0.7)]\n",
    "val_data = data[int(n * 0.7):int(n * 0.9)]\n",
    "test_data = data[int(n * 0.9):]\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "\n",
    "input_width = 6\n",
    "LABEL_OPTIONS = args.labels\n",
    "\n",
    "generator = WindowGenerator(input_width, LABEL_OPTIONS, mean, std)\n",
    "train_ds = generator.make_dataset(train_data, True)\n",
    "val_ds = generator.make_dataset(val_data, False)\n",
    "test_ds = generator.make_dataset(test_data, False)\n",
    "\n",
    "# Let's save datasets on disk\n",
    "tf.data.experimental.save(train_ds, './Lab4/th_train')\n",
    "tf.data.experimental.save(val_ds, './Lab4/th_val')\n",
    "tf.data.experimental.save(test_ds, './Lab4/th_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d28f7-60ec-49a5-aed6-ed132d2c5c8a",
   "metadata": {},
   "source": [
    "To load a previously saved dataset, you need to specify element_spec, a type signature of the elements of the saved dataset, which can be obtained via tf.data.Dataset.element_spec. This requirement exists so that shape inference of the loaded dataset does not need to perform I/O.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70180ae-ca85-492f-9991-d38ae862518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_specs = (tf.TensorSpec([None, 6, 2], dtype=tf.float32),\n",
    "                tf.TensorSpec([None, 2]))\n",
    "#train_ds = tf.data.experimental.load('./Lab4/th_train', tensor_specs)\n",
    "#val_ds = tf.data.experimental.load('./Lab4/th_val', tensor_specs)\n",
    "#test_ds = tf.data.experimental.load('./Lab4/th_test', tensor_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc5e2e-720f-4927-b7e7-ccbbfc3f3a47",
   "metadata": {},
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c609eabe-add4-4fe1-b5c3-502daef504e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_conv1d_1_input:0\n",
      "Input shape: [1 6 2]\n",
      "Output shape: [1 2]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/model_{}.tflite\".format(\"cnn_3\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "43c9a8e4-7589-48a0-b0af-0895d18a0a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size without ptq:  70492\n"
     ]
    }
   ],
   "source": [
    "print(\"File size without ptq: \", os.path.getsize(\"Lab4/models/model_{}.tflite\".format(\"cnn_3\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f563eb7-7be4-4947-811f-02aff9fbcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.experimental.load('./Lab4/th_test', tensor_specs)\n",
    "test_data = test_ds.map(lambda a, b: a)\n",
    "test_labels = test_ds.map(lambda a, b: b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d85b984-c6ec-4dcd-8b94-b06d2d9f2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.unbatch().batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da83dd-07d6-452f-bbe6-698cc3a79da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator())) # this fits in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700cb259-7f97-4152-b153-daac856bbdd0",
   "metadata": {},
   "source": [
    "Let's generate np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a87cd3a1-1aad-4bb2-93e4-4b12552e1fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_th(interpreter, test_data):\n",
    "    \n",
    "    for i, window in enumerate(test_data.as_numpy_iterator()):\n",
    "        interpreter.set_tensor(input_details[0]['index'], window)\n",
    "        interpreter.invoke()\n",
    "        predicted = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        if i==0:\n",
    "            preds = np.array(predicted, dtype=np.float32)\n",
    "        else:\n",
    "            preds = np.append(preds, predicted, axis=0)\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a93d99-c350-49a0-8fd4-b2444606fe22",
   "metadata": {},
   "source": [
    "TRY: np.array(list(dataset.as_numpy_iterator())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c5a1f70-4b3e-45c5-8c20-990b65b88212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculateMAE(actuals, preds):\n",
    "    \"\"\"\n",
    "    Calculate MAE between 2 np vectors.\n",
    "    np: numpy\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean(np.absolute(actuals - preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e1d654ce-1f87-4fa0-b0b0-3589c91d50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict_th(interpreter, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d50eeecb-9a72-4436-9ae0-b013a2685200",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature MAE:  0.25623897\n",
      "Humidity MAE:  0.7927708\n"
     ]
    }
   ],
   "source": [
    "print(\"Temperature MAE: \", calculateMAE(test_labels[:, 0], preds[:, 0]))\n",
    "print(\"Humidity MAE: \", calculateMAE(test_labels[:, 1], preds[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed74ff-b048-4fe4-940d-09f8bd175e85",
   "metadata": {},
   "source": [
    "**Now let's move on MFCCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0091abe0-796c-40cf-81a9-03cb7b969ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lab3.lab3_ex2_working_version import SignalGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9038afb-3c0e-479a-804b-f48094081542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Lab3.lab3_ex2_working_version import SignalGenerator\n",
    "\n",
    "data_dir = '/home/pi/WORK_DIR/notebooks/Ex_Gianlu/LABs/LAB 3/data/mini_speech_commands'\n",
    "\n",
    "filenames = tf.io.gfile.glob(data_dir + '/*/*')  # Return list of files matching the pattern\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "\n",
    "test_files = filenames[int(num_samples * 0.9):]\n",
    "\n",
    "LABELS = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "LABELS = LABELS[LABELS != 'README.md']\n",
    "LABELS = np.delete(LABELS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82734d21-b8eb-41c1-95a2-22178d58df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio shape without padding (None,)\n",
      "Audio shape with padding (16000,)\n"
     ]
    }
   ],
   "source": [
    "#STFT_OPTIONS = {'frame_length': 256, 'frame_step': 128, 'mfcc': False}\n",
    "MFCC_OPTIONS = {'frame_length': 640, 'frame_step': 320, 'mfcc': True,\n",
    "                'lower_frequency': 20, 'upper_frequency': 4000, 'num_mel_bins': 40,\n",
    "                'num_coefficients': 10}\n",
    "\n",
    "options = MFCC_OPTIONS\n",
    "\n",
    "generator = SignalGenerator(LABELS, 16000, **options)\n",
    "test_ds = generator.make_dataset(test_files, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9854d8b7-7d07-4a84-be9d-0cc657614dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_ds.map(lambda a, b: a)\n",
    "test_labels = test_ds.map(lambda a, b: b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54ba40a2-1513-487b-9967-1c4ba0b563b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator())) # this fits in memory\n",
    "test_data = test_data.unbatch().batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87595e69-cfe1-4a93-afe8-ac152fbda9a7",
   "metadata": {},
   "source": [
    "Let's test inference with tflite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b187d663-1fb4-4d98-8107-1564f022e1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_conv2d_input:0\n",
      "Input shape: [ 1 49 10  1]\n",
      "Output shape: [1 8]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/model_{}.tflite\".format(\"cnn_mfccs\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3bab5932-1df1-4d4a-8f59-7f2d7f8b4227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_from_mfccs(interpreter, test_data):\n",
    "    for i, mfccs in enumerate(test_data.as_numpy_iterator()):\n",
    "        interpreter.set_tensor(input_details[0]['index'], mfccs)\n",
    "        interpreter.invoke()\n",
    "        predicted = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "        if i==0:\n",
    "            preds = np.array(predicted, dtype=np.float32)\n",
    "        else:\n",
    "            preds = np.append(preds, predicted, axis=0)\n",
    "\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae62c026-9ee7-48cf-92ce-4d09c491008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(true_values, predictions):\n",
    "    N = true_values.shape[0]\n",
    "    return (true_values == predictions).sum() / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e50242d3-773e-4a29-8fc9-472131aa3059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1775"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(test_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c5db8-8ede-4121-84e9-fb6269500685",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27485583-8750-4440-b647-5176ba4ce186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only to convert:\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "03caed1f-423f-48a5-a6e3-7c514ec057a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: conv1d_input\n",
      "Input shape: [1 6 2]\n",
      "Output shape: [1 2]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/model_{}.tflite\".format(\"CNN_opt_ptq\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "090c63eb-4b2b-409a-b5fe-7903d8853643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size after ptq:  23952\n"
     ]
    }
   ],
   "source": [
    "print(\"File size after ptq: \", os.path.getsize(\"Lab4/models/model_{}.tflite\".format(\"CNN_opt_ptq\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "02905f08-241e-453d-97ba-8b952e0853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_specs = (tf.TensorSpec([None, 6, 2], dtype=tf.float32),\n",
    "                tf.TensorSpec([None, 2]))\n",
    "test_ds = tf.data.experimental.load('Lab4/th_test', tensor_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "06972ea2-e55f-4a11-b799-85981ff3764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_ds.map(lambda a, b: a)\n",
    "test_labels = test_ds.map(lambda a, b: b)\n",
    "test_data = test_data.unbatch().batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a37cd-c4b4-4c26-844c-0209a03ceceb",
   "metadata": {},
   "source": [
    "Latency and MAE for CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cd99756c-dd63-4e6e-89a0-a1108a99a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "preds = predict_th(interpreter, test_data)\n",
    "b = time.time()\n",
    "test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4d49d3d-790b-4e51-974b-5569da59e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature MAE:  0.93616277\n",
      "Humidity MAE:  0.95842415\n",
      "Latency for inference: 31.048535346984863 sec\n"
     ]
    }
   ],
   "source": [
    "temp_mae_pqt = calculateMAE(test_labels[:, 0], preds[:, 0])\n",
    "hum_mae_pqt = calculateMAE(test_labels[:, 1], preds[:, 1])\n",
    "print(\"Temperature MAE: \", temp_mae_pqt)\n",
    "print(\"Humidity MAE: \", hum_mae_pqt)\n",
    "print(\"Latency for inference: {} sec\".format(b-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba2287-d261-4b28-a667-474baef9ed5c",
   "metadata": {},
   "source": [
    "# 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be1bc88-5d87-4b43-82c2-506711edd27a",
   "metadata": {},
   "source": [
    "**TEMP AND HUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef741aa-bf15-420d-9052-471f7a5edba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only to convert in tf lite weight + activ. optimization:\n",
    "def representative_dataset_gen():\n",
    "     for x, _ in train_ds.unbatch().batch(1).take(1000):\n",
    "         yield [x]\n",
    "        \n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4a1ab87b-71dd-4615-9494-0eea4426976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size after ptq weights and activations:  21752\n"
     ]
    }
   ],
   "source": [
    "print(\"File size after ptq weights and activations: \", os.path.getsize(\"Lab4/models/{}.tflite\".format(\"cnn_weight_act_opt_th\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "145f2dcc-bd76-479c-884a-91fb67c130c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_x:0\n",
      "Input shape: [1 6 2]\n",
      "Output shape: [1 2]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/{}.tflite\".format(\"cnn_weight_act_opt_th\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49cc7309-5e56-4815-93ba-a39a79ba0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = time.time()\n",
    "preds = predict_th(interpreter, test_data)\n",
    "b = time.time()\n",
    "#test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bf211b82-29e1-403c-8e30-d8788361f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature MAE:  0.93616277\n",
      "Humidity MAE:  0.95842415\n",
      "Latency for inference: 30.628411531448364 sec\n"
     ]
    }
   ],
   "source": [
    "temp_mae_weights_act_cnn = calculateMAE(test_labels[:, 0], preds[:, 0])\n",
    "hum_mae_weights_act_cnn = calculateMAE(test_labels[:, 1], preds[:, 1])\n",
    "print(\"Temperature MAE: \", temp_mae_pqt)\n",
    "print(\"Humidity MAE: \", hum_mae_pqt)\n",
    "print(\"Latency for inference: {} sec\".format(b-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe3327-176e-4e14-851c-6abce673c8df",
   "metadata": {},
   "source": [
    "MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ee4800a9-717f-4860-bee0-0083cd177226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs: 1\n",
      "Number of outputs: 1\n",
      "Input name: serving_default_x:0\n",
      "Input shape: [1 6 2]\n",
      "Output shape: [1 2]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/{}.tflite\".format(\"mlp_weight_act_opt_th\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ca7a6228-80d0-4243-816f-676c8c4af661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size after ptq weights and activations:  21680\n"
     ]
    }
   ],
   "source": [
    "print(\"File size after ptq weights and activations: \", os.path.getsize(\"Lab4/models/{}.tflite\".format(\"mlp_weight_act_opt_th\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "583ce568-a791-47b0-b7c0-5f04608f48f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature MAE:  0.93616277\n",
      "Humidity MAE:  0.95842415\n",
      "Latency for inference: 30.431209325790405 sec\n"
     ]
    }
   ],
   "source": [
    "a = time.time()\n",
    "preds = predict_th(interpreter, test_data)\n",
    "b = time.time()\n",
    "#test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator()))\n",
    "temp_mae_weights_act_cnn = calculateMAE(test_labels[:, 0], preds[:, 0])\n",
    "hum_mae_weights_act_cnn = calculateMAE(test_labels[:, 1], preds[:, 1])\n",
    "print(\"Temperature MAE: \", temp_mae_pqt)\n",
    "print(\"Humidity MAE: \", hum_mae_pqt)\n",
    "print(\"Latency for inference: {} sec\".format(b-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e84420-2fe6-410b-883a-37b6bd796df4",
   "metadata": {},
   "source": [
    "LSTM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8a6bbddd-6565-4aed-99ef-e338c5923e1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tensorflow/lite/kernels/unidirectional_sequence_lstm.cc:293 input->type != kTfLiteFloat32 (INT8 != FLOAT32)Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.\ntensorflow/lite/kernels/unidirectional_sequence_lstm.cc:293 input->type != kTfLiteFloat32 (INT8 != FLOAT32)Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-c8127200a324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lab4/models/{}.tflite\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm_weight_act_opt_th\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/WORK_DIR/py37/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mallocate_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllocateTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_safe_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensorflow/lite/kernels/unidirectional_sequence_lstm.cc:293 input->type != kTfLiteFloat32 (INT8 != FLOAT32)Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.\ntensorflow/lite/kernels/unidirectional_sequence_lstm.cc:293 input->type != kTfLiteFloat32 (INT8 != FLOAT32)Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"Lab4/models/{}.tflite\".format(\"lstm_weight_act_opt_th\"))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "                                  \n",
    "print(\"Number of inputs:\", len(input_details))\n",
    "print(\"Number of outputs:\", len(output_details))\n",
    "print(\"Input name:\", input_details[0]['name'])\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])\n",
    "\n",
    "print(\"File size after ptq weights and activations: \", os.path.getsize(\"Lab4/models/{}.tflite\".format(\"lstm_weight_act_opt_th\")))\n",
    "\n",
    "a = time.time()\n",
    "preds = predict_th(interpreter, test_data)\n",
    "b = time.time()\n",
    "#test_labels = np.array(list(test_labels.unbatch().as_numpy_iterator()))\n",
    "temp_mae_weights_act_cnn = calculateMAE(test_labels[:, 0], preds[:, 0])\n",
    "hum_mae_weights_act_cnn = calculateMAE(test_labels[:, 1], preds[:, 1])\n",
    "print(\"Temperature MAE: \", temp_mae_pqt)\n",
    "print(\"Humidity MAE: \", hum_mae_pqt)\n",
    "print(\"Latency for inference: {} sec\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ff6c8-79b1-474a-bedb-fdc54b43da8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
